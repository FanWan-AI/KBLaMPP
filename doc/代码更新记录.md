### 版本1.1
- 时间：2025-11-19 14：55
#### 代码改动内容
目前，我已通过打通数据、训练和编码层，正式启动了KBLaM++计划B的实施，现已能实现端到端的全流程运行。

**阶段总结**

- **数据流水线**：dataloader.py现已可读取JSONL格式的问答记录，使用主干分词器对问题/答案对进行分词处理，支持批次填充，并为阶段A训练提供问题时间窗口及注意力掩码。
- **训练循环**：train_stageA.py加载分词器，将真实输入数据送入KBInjected模型，结合注意力掩码与问题时间参数进行运算，并采用规范的交叉熵损失函数替代原有的虚拟张量逻辑。
- **知识注入机制**：injection_wrapper.py现已集成d_ctx维度与Top-k配置模块，通过选择器处理真实问题时间窗口数据，并将门控知识库注意力融合回主干隐藏状态。
- **离线编码**：encode_kv.py运行HuggingFace句子编码器，对五元组时间窗口进行时间编码，通过轻量级MLP网络生成键值向量，确保存储输出可直接供给FAISS与KBSelector使用。

**后续推进重点**

1. 完成离线构建/索引脚本的对接（包括生成合成问答数据、编码五元组、构建FAISS索引），为阶段A训练提供真实数据支撑
2. 扩展KBInjectedModel以支持多注入层架构、残差处理机制，并增强与主干模型的交互能力（如按需传递layer_past参数）
3. 封装快速验证指令（训练+评估流程），完善数据集格式与配置参数的文档说明，确保团队可复现全工作流
4. 持续跟进既定事项清单，同步更新进展状态并锁定剩余交付目标

**测试进展**
- 尚未实际运行（需依赖当前环境暂未构建的HuggingFace模型、FAISS知识库及特定数据集）
  
### 版本v1.2
- 时间：2025-11-19 15：07
  
#### 代码改动内容
  **encode_kv.py**：已重构该脚本，采用统一简洁的实现方案——检测torch/transformers环境，优先通过HuggingFace计算上下文嵌入向量，若无条件则自动降级为确定性随机向量生成；针对两种场景均集成TauEncoder分支及因果辅助功能（包括文本编码、随机回退机制、元数据读取器）。

**上下文处理**：新增投影层，将原始上下文编码器输出降维至预设的d_ctx维度后再存储上下文向量，确保元数据维度与模型预期保持兼容。

**后续推进重点**

重启流水线：在完成torch/transformers环境部署后，需依次执行：
1. 运行 `python encode_kv.py <五元组文件> <输出目录>`（例如处理合成数据集）
2. 通过 `python offline/build_index.py` 构建FAISS知识库
3. 完成前述步骤后方可启动阶段A的训练任务


### v1.2 当前进度分析
**项目进展分析与后续建议**

**当前状态概览**

- **数据资产**：已存在合成五元组数据（synth_world.jsonl）及问答分割文件（data/qa/synth_world_*.jsonl），其格式符合理论文档定义的标准。但Hotpot、T-REx及TimeQA数据集的转换脚本（offline/build_5tuple_from_*.py）仍处于框架草稿阶段，尚待实现具体功能。
- **离线编码与索引**：encode_kv.py现已实现基于HuggingFace的完整处理流水线（含确定性回退机制），能够对头实体/关系/尾实体/上下文进行编码，将其投影至d_k/d_v/d_ctx维度，并存储为NumPy数据块及元数组。build_index.py虽可将键向量封装为FAISS索引，但尚未生成可直接使用的store/目录，导致阶段A目前无法实际获取键值数据。
- **核心知识库模块**：kblampp包已包含可运行的基础实现，包括FAISS支持的KnowledgeIndex、内存映射KBValueStore、selector.py/scorers.py中的语义/上下文/时间评分机制，以及简易KBFusionLayer。当前仅支持单层注入，且默认主干模型暴露backbone.model.layers结构（部分LLaMA检查点符合此假设，但Qwen等变体可能不兼容）。
- **训练循环**：train_stageA.py已完成分词器、数据加载器、知识模块及封装器的初步对接。代码中存在硬编码设定（单注入层、CPU端即时FAISS查询、未实现梯度累积），且因YAML配置尚未传递问答路径，需手动通过--dataset参数指定数据源。阶段B的训练脚本目前完全缺失。
- **评估与推理**：eval和infer目录下的脚本仍为桩模块，仅生成模拟预测结果或随机证据链，可用于展示预期输入输出格式，但无法实际验证模型性能。
- **文档与追踪**：kblamppo理论总览.md、kblampp-planB.md、kblampp-implementation-guide.md及代码更新记录.md内容详实且持续更新。版本1.2的更新日志明确要求“重启流水线：encode → build_index → Stage A”，实施指南中已锁定Plan B三阶段规划（阶段1合成世界、阶段2 Hotpot/TimeQA、阶段3演示）。

**缺失环节与潜在风险**

- **离线流水线未经验证**：由于缺少实际store/目录（键值/元数据+FAISS索引），近邻检索与知识库选择功能均无法运行。训练脚本一旦尝试加载store/index_hnsw将立即崩溃。
- **主干模型集成脆弱性**：KBInjectedModel直接调用self.backbone.model.layers结构并手动操作lm_head，此实现无法兼容所有HuggingFace架构（如Qwen使用transformer.blocks，且部分模型依赖past_key_values）。目前尚未支持多层注入或多令牌缓存机制。
- **配置与命令行参数不匹配**：数据集路径虽定义于configs/*.yaml，但train_stageA.py未读取这些配置，必须通过命令行手动指定。梯度累积等超参数虽在YAML中定义，但实际未被使用。
- **评估工具链缺失**：由于eval_qa.py与dump_evidence.py仍为桩模块，训练启动后缺乏自动化的精确匹配/F1值验证及证据链检查机制。
- **下游脚本未实现**：Hotpot/TimeQA/T-REx数据转换器、阶段B训练及infer_server.py均处于待开发状态，导致无法向合成世界之外拓展。

**推荐优先实施的模块**
应优先完善离线存储与近邻索引构建模块，为阶段A在合成世界上实现端到端运行奠定基础：

1. **参数化encode_kv.py与build_index.py**：从synth_world.yaml读取embedding_model、d_k/d_v/d_ctx等参数及文件路径，将输出统一存储至store/synth_world/目录（包含键值/元数据及index_hnsw索引）。
2. **新增流程协调器**（如offline/run_pipeline.py）：根据数据集配置依次调用编码→索引构建→完整性检查流程，并将产出物路径记录至配置文件。
3. **对接训练流程与产出物**：改造train_stageA.py使其从同一YAML文件读取存储路径（无需手动--dataset），并验证键值/元数据/FAISS文件是否存在，缺失时提供清晰报错。
4. **执行冒烟测试**：在synth_world.jsonl上运行完整离线流水线，确认FAISS查询返回合理键值后，再开展多层注入或阶段B的开发工作。

完成此模块将直接解锁实际实验功能，为选择器提供真实张量数据，同时满足代码更新记录中“后续推进重点”的首项要求，并为后续数据集处理提供可复用的标准化产出。

**质量门禁状态**
- **构建**：未执行（本次仅为分析，无代码变更）
- **代码规范/类型检查**：未执行（未修改代码）
- **测试**：未执行；评估脚本仍为桩模块

请指示接下来优先部署离线流水线还是深入开发注入封装器。

### 版本1.3
- 时间：2025-11-19 16：40

#### 代码改动内容
- 在 `configs/synth_world.yaml` 中新增 `store` 与 `pipeline` 段，统一存放键值、索引目录、编码维度及合成世界/QA 生成参数；后续数据集可以复用同一结构。
- 新增 `offline/run_pipeline.py`，按配置依次运行 `gen_synth_world.py`、`gen_synth_qa.py`、`encode_kv.py` 与 `build_index.py`，支持 `--steps` 与 `--force` 控制，实现“生成合成问答数据 → 编码五元组 → 构建 FAISS 索引”的一键化流程。
- 重构 `train/train_stageA.py`：自动从数据集配置读取 QA、store 与索引路径，启动前校验 K/V/meta/index 是否齐全，并支持 `grad_accum`、`max_steps` 等超参；命令行仅需 `--config` 即可衔接离线产出物。
- 在 `README.md` 中补充运行 `offline/run_pipeline.py` 的指导，提示如何覆盖或跳过指定阶段。

#### 后续推进重点
1. 在合成 world 上执行 `python offline/run_pipeline.py --config configs/synth_world.yaml --force`，验证整条链路（包含 FAISS 构建）产物，随后运行 `python train/train_stageA.py --config configs/synth_world.yaml` 完成首轮训练冒烟测试。
2. 以 Hotpot/TimeQA 配置为模板，逐条补齐 `store`/`pipeline` 字段并实现对应的 `build_5tuple_from_*.py` 逻辑，确保这些数据源也能使用统一流水线。
3. 扩展 `KBInjectedModel` 支持多注入层与 `past_key_values` 交互，为 Qwen 等主干提供更稳健封装。
4. 将评测与证据链脚本从桩模块升级为可调用 KBInjectedModel 的真实实现，形成“训练→评测→可解释输出”的闭环。

**测试进展**
- 本次改动仅涉及脚本与配置，尚未执行实际 encode/index/训练命令；待流水线脚本部署完毕后需完成一次端到端冒烟。

### v1.3 当前代码分析
已梳理v1.3变更日志及理论/Plan B文档，现制定如下推进方案：（1）端到端验证新版离线流水线；（2）在合成世界上进行阶段A训练冒烟测试；（3）按计划展开Hotpot/TimeQA数据集成与多层注入功能开发。

**当前就绪状态**

- 代码更新记录.md v1.3确认了新增配置字段、run_pipeline.py及重构后的train_stageA.py，但明确标注尚未实际执行编码/索引/训练命令
- synth_world.yaml虽已关联既有五元组及问答JSONL文件（data/5tuple/synth_world.jsonl, data/qa/synth_world_*.jsonl），但store/synth_world/目录及其FAISS子目录尚未生成，导致阶段A训练将在train_stageA.py的产出物校验环节失败
- 主干模型与选择器配置现已归入backbone_llama1b.yaml；训练器支持通过单一--config参数自动运行，并在store/index就绪后无需手动指定数据集参数

**待执行测试流程**（需先安装torch/transformers/faiss-cpu等依赖）

1. 执行完整流水线：`python run_pipeline.py --config configs/synth_world.yaml --force`  
   （该命令将重新生成五元组、问答分割、通过encode_kv.py编码键值、经offline/build_index.py构建FAISS索引。若仅需更新嵌入向量或近邻存储，后续可使用`--steps encode index`参数）

2. 启动阶段A训练：`python train_stageA.py --config configs/synth_world.yaml --max_steps 50`  
   （该命令将从配置读取全部路径，验证存储/索引状态，运行冻结主干的阶段A训练循环。建议首次运行设置较小步数以验证全链路连通性）

注：因当前环境未安装HuggingFace+FAISS依赖，尚未在本地执行上述命令

**冒烟测试后的开发重点**

1. **通用化流水线配置**：将synth_world.yaml中的存储/流水线配置块复制至hotpot.yaml/timeqa.yaml/trex.yaml，完善对应offline/build_5tuple_from_*.py脚本，实现各数据集无缝接入run_pipeline.py
2. **强化知识注入机制**：扩展kblampp.injection_wrapper.KBInjectedModel以支持多注入层、适配past_key_values传输，并使融合头模块可根据主干配置动态参数化（对应理论文档§§4.4–4.6及v1.3后续推进重点）
3. **阶段B与评估工具链**：新增train_stageB.py（支持LoRA或顶层解冻），实现eval/eval_qa.py/dump_evidence.py/visualize_alpha.py的实际功能，以达成理论规范要求的精确匹配/F1评估及证据链导出
4. **回归测试与文档沉淀**：在合成流水线验证通过后，于doc/kblampp-implementation-guide.md中记录精确命令与预期产出物，并建立轻量回归测试集（仅需10条问答样例）用于保障后续索引变更

请待torch/transformers/faiss环境就绪后告知，我将协助推进流水线测试与多数据集配置迭代。

### 环境安装
**方案概述**

- **依赖清单**：根据文档与代码分析，需要以下关键包：
  `numpy`, `pyyaml`, `typing-extensions`, `torch`, `transformers`, `sentencepiece`, `huggingface-hub`, `faiss-cpu`, `bitsandbytes`, `accelerate`, `peft`, `sentence-transformers`
  这些依赖覆盖离线流水线、编码逻辑、FAISS封装器及阶段A训练桩模块的全部需求
- **依赖管理文件**：在代码库根目录新增requirements.txt，其中包含版本锁定的依赖包列表，您可在激活conda环境后直接通过`pip install -r requirements.txt`完成安装

**环境配置流程**

1. 创建并激活conda环境（PowerShell）：
```powershell
conda create -n kblampp-planb python=3.10 -y
conda activate kblampp-planb
```

1. 可选GPU优化提示：在Windows RTX 4090环境下，建议在执行pip安装前显式安装CUDA版torch：
```powershell
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```
此操作可确保与bitsandbytes及4090的CUDA驱动兼容

**注意事项**：bitsandbytes需匹配对应的CUDA工具链，默认使用faiss-cpu版本（后续可按需切换至faiss-gpu）。合成问答数据生成与离线脚本均依赖上述安装包，因此通过单次`pip install -r requirements.txt`即可满足Plan B框架的全功能需求。

