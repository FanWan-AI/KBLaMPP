### 版本1.1
- 时间：2025-11-19 14：55
#### 代码改动内容
目前，我已通过打通数据、训练和编码层，正式启动了KBLaM++计划B的实施，现已能实现端到端的全流程运行。

**阶段总结**

- **数据流水线**：dataloader.py现已可读取JSONL格式的问答记录，使用主干分词器对问题/答案对进行分词处理，支持批次填充，并为阶段A训练提供问题时间窗口及注意力掩码。
- **训练循环**：train_stageA.py加载分词器，将真实输入数据送入KBInjected模型，结合注意力掩码与问题时间参数进行运算，并采用规范的交叉熵损失函数替代原有的虚拟张量逻辑。
- **知识注入机制**：injection_wrapper.py现已集成d_ctx维度与Top-k配置模块，通过选择器处理真实问题时间窗口数据，并将门控知识库注意力融合回主干隐藏状态。
- **离线编码**：encode_kv.py运行HuggingFace句子编码器，对五元组时间窗口进行时间编码，通过轻量级MLP网络生成键值向量，确保存储输出可直接供给FAISS与KBSelector使用。

**后续推进重点**

1. 完成离线构建/索引脚本的对接（包括生成合成问答数据、编码五元组、构建FAISS索引），为阶段A训练提供真实数据支撑
2. 扩展KBInjectedModel以支持多注入层架构、残差处理机制，并增强与主干模型的交互能力（如按需传递layer_past参数）
3. 封装快速验证指令（训练+评估流程），完善数据集格式与配置参数的文档说明，确保团队可复现全工作流
4. 持续跟进既定事项清单，同步更新进展状态并锁定剩余交付目标

**测试进展**
- 尚未实际运行（需依赖当前环境暂未构建的HuggingFace模型、FAISS知识库及特定数据集）
  
### 版本v1.2
- 时间：2025-11-19 15：07
  
#### 代码改动内容
  **encode_kv.py**：已重构该脚本，采用统一简洁的实现方案——检测torch/transformers环境，优先通过HuggingFace计算上下文嵌入向量，若无条件则自动降级为确定性随机向量生成；针对两种场景均集成TauEncoder分支及因果辅助功能（包括文本编码、随机回退机制、元数据读取器）。

**上下文处理**：新增投影层，将原始上下文编码器输出降维至预设的d_ctx维度后再存储上下文向量，确保元数据维度与模型预期保持兼容。

**后续推进重点**

重启流水线：在完成torch/transformers环境部署后，需依次执行：
1. 运行 `python encode_kv.py <五元组文件> <输出目录>`（例如处理合成数据集）
2. 通过 `python offline/build_index.py` 构建FAISS知识库
3. 完成前述步骤后方可启动阶段A的训练任务


### v1.2 当前进度分析
**项目进展分析与后续建议**

**当前状态概览**

- **数据资产**：已存在合成五元组数据（synth_world.jsonl）及问答分割文件（data/qa/synth_world_*.jsonl），其格式符合理论文档定义的标准。但Hotpot、T-REx及TimeQA数据集的转换脚本（offline/build_5tuple_from_*.py）仍处于框架草稿阶段，尚待实现具体功能。
- **离线编码与索引**：encode_kv.py现已实现基于HuggingFace的完整处理流水线（含确定性回退机制），能够对头实体/关系/尾实体/上下文进行编码，将其投影至d_k/d_v/d_ctx维度，并存储为NumPy数据块及元数组。build_index.py虽可将键向量封装为FAISS索引，但尚未生成可直接使用的store/目录，导致阶段A目前无法实际获取键值数据。
- **核心知识库模块**：kblampp包已包含可运行的基础实现，包括FAISS支持的KnowledgeIndex、内存映射KBValueStore、selector.py/scorers.py中的语义/上下文/时间评分机制，以及简易KBFusionLayer。当前仅支持单层注入，且默认主干模型暴露backbone.model.layers结构（部分LLaMA检查点符合此假设，但Qwen等变体可能不兼容）。
- **训练循环**：train_stageA.py已完成分词器、数据加载器、知识模块及封装器的初步对接。代码中存在硬编码设定（单注入层、CPU端即时FAISS查询、未实现梯度累积），且因YAML配置尚未传递问答路径，需手动通过--dataset参数指定数据源。阶段B的训练脚本目前完全缺失。
- **评估与推理**：eval和infer目录下的脚本仍为桩模块，仅生成模拟预测结果或随机证据链，可用于展示预期输入输出格式，但无法实际验证模型性能。
- **文档与追踪**：kblamppo理论总览.md、kblampp-planB.md、kblampp-implementation-guide.md及代码更新记录.md内容详实且持续更新。版本1.2的更新日志明确要求“重启流水线：encode → build_index → Stage A”，实施指南中已锁定Plan B三阶段规划（阶段1合成世界、阶段2 Hotpot/TimeQA、阶段3演示）。

**缺失环节与潜在风险**

- **离线流水线未经验证**：由于缺少实际store/目录（键值/元数据+FAISS索引），近邻检索与知识库选择功能均无法运行。训练脚本一旦尝试加载store/index_hnsw将立即崩溃。
- **主干模型集成脆弱性**：KBInjectedModel直接调用self.backbone.model.layers结构并手动操作lm_head，此实现无法兼容所有HuggingFace架构（如Qwen使用transformer.blocks，且部分模型依赖past_key_values）。目前尚未支持多层注入或多令牌缓存机制。
- **配置与命令行参数不匹配**：数据集路径虽定义于configs/*.yaml，但train_stageA.py未读取这些配置，必须通过命令行手动指定。梯度累积等超参数虽在YAML中定义，但实际未被使用。
- **评估工具链缺失**：由于eval_qa.py与dump_evidence.py仍为桩模块，训练启动后缺乏自动化的精确匹配/F1值验证及证据链检查机制。
- **下游脚本未实现**：Hotpot/TimeQA/T-REx数据转换器、阶段B训练及infer_server.py均处于待开发状态，导致无法向合成世界之外拓展。

**推荐优先实施的模块**
应优先完善离线存储与近邻索引构建模块，为阶段A在合成世界上实现端到端运行奠定基础：

1. **参数化encode_kv.py与build_index.py**：从synth_world.yaml读取embedding_model、d_k/d_v/d_ctx等参数及文件路径，将输出统一存储至store/synth_world/目录（包含键值/元数据及index_hnsw索引）。
2. **新增流程协调器**（如offline/run_pipeline.py）：根据数据集配置依次调用编码→索引构建→完整性检查流程，并将产出物路径记录至配置文件。
3. **对接训练流程与产出物**：改造train_stageA.py使其从同一YAML文件读取存储路径（无需手动--dataset），并验证键值/元数据/FAISS文件是否存在，缺失时提供清晰报错。
4. **执行冒烟测试**：在synth_world.jsonl上运行完整离线流水线，确认FAISS查询返回合理键值后，再开展多层注入或阶段B的开发工作。

完成此模块将直接解锁实际实验功能，为选择器提供真实张量数据，同时满足代码更新记录中“后续推进重点”的首项要求，并为后续数据集处理提供可复用的标准化产出。



### 版本1.3
- 时间：2025-11-19 16：40

#### 代码改动内容
- 在 `configs/synth_world.yaml` 中新增 `store` 与 `pipeline` 段，统一存放键值、索引目录、编码维度及合成世界/QA 生成参数；后续数据集可以复用同一结构。
- 新增 `offline/run_pipeline.py`，按配置依次运行 `gen_synth_world.py`、`gen_synth_qa.py`、`encode_kv.py` 与 `build_index.py`，支持 `--steps` 与 `--force` 控制，实现“生成合成问答数据 → 编码五元组 → 构建 FAISS 索引”的一键化流程。
- 重构 `train/train_stageA.py`：自动从数据集配置读取 QA、store 与索引路径，启动前校验 K/V/meta/index 是否齐全，并支持 `grad_accum`、`max_steps` 等超参；命令行仅需 `--config` 即可衔接离线产出物。
- 在 `README.md` 中补充运行 `offline/run_pipeline.py` 的指导，提示如何覆盖或跳过指定阶段。

#### 后续推进重点
1. 在合成 world 上执行 `python offline/run_pipeline.py --config configs/synth_world.yaml --force`，验证整条链路（包含 FAISS 构建）产物，随后运行 `python train/train_stageA.py --config configs/synth_world.yaml` 完成首轮训练冒烟测试。
2. 以 Hotpot/TimeQA 配置为模板，逐条补齐 `store`/`pipeline` 字段并实现对应的 `build_5tuple_from_*.py` 逻辑，确保这些数据源也能使用统一流水线。
3. 扩展 `KBInjectedModel` 支持多注入层与 `past_key_values` 交互，为 Qwen 等主干提供更稳健封装。
4. 将评测与证据链脚本从桩模块升级为可调用 KBInjectedModel 的真实实现，形成“训练→评测→可解释输出”的闭环。

**测试进展**
- 本次改动仅涉及脚本与配置，尚未执行实际 encode/index/训练命令；待流水线脚本部署完毕后需完成一次端到端冒烟。

### v1.3 当前代码分析
已梳理v1.3变更日志及理论/Plan B文档，现制定如下推进方案：（1）端到端验证新版离线流水线；（2）在合成世界上进行阶段A训练冒烟测试；（3）按计划展开Hotpot/TimeQA数据集成与多层注入功能开发。

**当前就绪状态**

- 代码更新记录.md v1.3确认了新增配置字段、run_pipeline.py及重构后的train_stageA.py，但明确标注尚未实际执行编码/索引/训练命令
- synth_world.yaml虽已关联既有五元组及问答JSONL文件（data/5tuple/synth_world.jsonl, data/qa/synth_world_*.jsonl），但store/synth_world/目录及其FAISS子目录尚未生成，导致阶段A训练将在train_stageA.py的产出物校验环节失败
- 主干模型与选择器配置现已归入backbone_llama1b.yaml；训练器支持通过单一--config参数自动运行，并在store/index就绪后无需手动指定数据集参数

**待执行测试流程**（需先安装torch/transformers/faiss-cpu等依赖）

1. 执行完整流水线：`python run_pipeline.py --config configs/synth_world.yaml --force`  
   （该命令将重新生成五元组、问答分割、通过encode_kv.py编码键值、经offline/build_index.py构建FAISS索引。若仅需更新嵌入向量或近邻存储，后续可使用`--steps encode index`参数）

2. 启动阶段A训练：`python train_stageA.py --config configs/synth_world.yaml --max_steps 50`  
   （该命令将从配置读取全部路径，验证存储/索引状态，运行冻结主干的阶段A训练循环。建议首次运行设置较小步数以验证全链路连通性）

注：因当前环境未安装HuggingFace+FAISS依赖，尚未在本地执行上述命令

**冒烟测试后的开发重点**

1. **通用化流水线配置**：将synth_world.yaml中的存储/流水线配置块复制至hotpot.yaml/timeqa.yaml/trex.yaml，完善对应offline/build_5tuple_from_*.py脚本，实现各数据集无缝接入run_pipeline.py
2. **强化知识注入机制**：扩展kblampp.injection_wrapper.KBInjectedModel以支持多注入层、适配past_key_values传输，并使融合头模块可根据主干配置动态参数化（对应理论文档§§4.4–4.6及v1.3后续推进重点）
3. **阶段B与评估工具链**：新增train_stageB.py（支持LoRA或顶层解冻），实现eval/eval_qa.py/dump_evidence.py/visualize_alpha.py的实际功能，以达成理论规范要求的精确匹配/F1评估及证据链导出
4. **回归测试与文档沉淀**：在合成流水线验证通过后，于doc/kblampp-implementation-guide.md中记录精确命令与预期产出物，并建立轻量回归测试集（仅需10条问答样例）用于保障后续索引变更



### 环境安装
**方案概述**

- **依赖清单**：根据文档与代码分析，需要以下关键包：
  `numpy`, `pyyaml`, `typing-extensions`, `torch`, `transformers`, `sentencepiece`, `huggingface-hub`, `faiss-cpu`, `bitsandbytes`, `accelerate`, `peft`, `sentence-transformers`
  这些依赖覆盖离线流水线、编码逻辑、FAISS封装器及阶段A训练桩模块的全部需求
- **依赖管理文件**：在代码库根目录新增requirements.txt，其中包含版本锁定的依赖包列表，您可在激活conda环境后直接通过`pip install -r requirements.txt`完成安装

**环境配置流程**

1. 创建并激活conda环境（PowerShell）：
```powershell
conda create -n kblampp-planb python=3.10 -y
conda activate kblampp-planb
```

1. 可选GPU优化提示：在Windows RTX 4090环境下，建议在执行pip安装前显式安装CUDA版torch：
```powershell
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```
此操作可确保与bitsandbytes及4090的CUDA驱动兼容

**注意事项**：bitsandbytes需匹配对应的CUDA工具链，默认使用faiss-cpu版本（后续可按需切换至faiss-gpu）。合成问答数据生成与离线脚本均依赖上述安装包，因此通过单次`pip install -r requirements.txt`即可满足Plan B框架的全功能需求。


### 版本v1.4 
时间：2025-11-19 21:20

已修复流水线配置加载机制，使其能基于代码库根目录解析相对路径，同时优化了encode_kv.py代码结构，并确保build_index.py在offline/目录下启动时能正常导入kblampp模块。

**修复详情**

- **配置路径解析**：run_pipeline.py现已将相对配置路径统一基于ROOT目录进行解析，这意味着无论当前工作目录在何处，执行 `python run_pipeline.py --config configs/synth_world.yaml` 均可正常运作
- **编码器修复**：上下文投影器现已在torch.no_grad()环境下运行，确保其NumPy转换过程不会因张量残留梯度需求而报错
- **索引构建导入**：build_index.py启动时自动将代码库根目录加入sys.path，从而避免在offline/目录独立运行该脚本时出现模块导入错误

**测试验证**

在offline/目录下执行：  
`python run_pipeline.py --config configs/synth_world.yaml --force`  
→ 流水线现已能无错误地生成合成数据、编码键值张量并构建FAISS索引


### v1.5 解决rel_ids.npy；entity_ids.npy都是一个数字全为0的维度数组+代码注释问题 
时间：2025-11-20 10：54

#### 解决rel_ids.npy；entity_ids.npy都是一个数字全为0的维度数组 
正在修复元数据导出功能，使合成知识库能记录真实的实体/关系ID，并重新运行流水线以验证输出结果。

**元数据映射改进**：encode_kv.py 现已追踪每个事实的头实体ID与关系ID，构建紧凑的整数映射表，并将其存储至 store/<dataset>/meta/entity_ids.npy 与 rel_ids.npy 文件中，不再使用零数组填充；同时确保上下文投影器在无梯度环境下运行。

**流水线输出验证**：在激活 conda kblampp 环境后，重新执行 `python run_pipeline.py --config configs/synth_world.yaml --force`，成功生成包含新元数据的知识库存储。通过简短Python脚本验证确认数组现已包含多样化的ID数据。

**测试流程**：
1. 执行 `python run_pipeline.py --config configs/synth_world.yaml --force`
2. 运行 `python -c "import numpy as np; ..."`（具体命令见内联代码）以输出唯一ID计数统计

**后续拓展建议**：若未来需要尾实体ID支持，或需在其他场景复用相同ID映射机制，可扩展 build_id_sequence 功能以包含这些字段，使选择器的实体嵌入能够覆盖事实中的所有参与元素。

#### 代码注释
已为Plan B技术栈的所有核心模块添加了全面的代码内文档，使后续开发人员无需频繁查阅理论文档即可理解各模块的协同工作机制。

**核心文档增强要点**：

- **kblampp核心模块**：knowledge_index.py、kb_store.py、selector.py、scorers.py、fusion.py及injection_wrapper.py现已详细说明近邻搜索算法选型、内存映射使用规范、多分支融合机制、评分启发式策略，以及自动梯度计算注意事项（如为何在FAISS查询前分离梯度）
- **训练链路**：dataloader.py与train_stageA.py新增关于数据集格式要求、截断/填充决策、句尾标记处理、阶段A冻结原理的说明——包括梯度累积实现机制及知识库存储与训练循环的对接逻辑
- **离线流水线**：encode_kv.py补充了ID重映射、元数据序列化及无梯度计算区的注释；run_pipeline.py完善了配置解析机制的说明，便于团队成员从任意目录调用流水线



### V1.6
- 2025-11-20 14:42
**LLM五元组生成器**

新增gen_world_llm.py独立脚本，该工具具备以下特性：
- 构建结构化DashScope提示模板，调用LocalGPT接口
- 从回复中提取首个JSON对象并进行必填字段验证
- 同步输出完整世界描述JSON及五元组JSONL列表
- 提示模板严格规范实体/事实数量、ID命名规则、时间跨度及可读证据片段，确保下游流水线自动获得更高质量的输入数据
- 命令行参数支持输出路径、实体/事实数量目标及运行时配置（包括模型选择、端点地址、解码参数），为后续提示模板迭代保留灵活性

**后续可执行步骤**：

1. 运行 `python gen_world_llm.py --output data/5tuple/synth_world_llm.jsonl` 以验证DashScope连接状态并检查生成的五元组数据
2. 将新生成的JSONL路径配置到synth_world.yaml（或新建配置），使run_pipeline.py与阶段A训练能获取新数据集
3. 扩展验证逻辑（如关系词汇表检查）或添加重试机制，以应对模型偶尔返回畸形JSON的情况

### V1.7 使用qwen-plus成功生成少量示例五元组
- 时间：2025-11-20 
**数据审查完成**——gen_world_llm.py现已实现完整运行，成功生成synth_world_llm.json（包含18个实体的目录）及synth_world_llm.jsonl（含80条五元组）。每个JSONL行均符合预期数据规范（头实体/关系/尾实体/上下文/时间窗口，采用ISO日期格式），关系ID从R0001开始顺序编号，文件结构完全符合下游加载器的要求。

**质量评估**：

优势：
- 实体类型覆盖全面（人物/组织/地点/事件/角色/日期）
- 存在多跳关系路径（如Nova Dynamics → Project Aether → Global initiatives，Elara Voss → Nova Dynamics → Tycho Outpost）
- 证据语句描述清晰，包含具体数字与日期

待改进点：
- 模型对部分事实仅进行措辞微调后重复生成（如多次出现“Nova Dynamics资助Dr. Elara Voss”或重复的Tycho承办事件）。若需严格去重，可增加后处理过滤器（基于头实体ID、关系名称、尾实体ID、起始时间的哈希值），并仅重新请求缺失部分
- 时间窗口集中在2027-2045年间，虽符合未来场景设定，但需注意阶段A配置当前默认使用2005-2024年。若时间匹配度关键，需在提示词中严格限定日期或添加验证器

**后续行动建议**：

1. **问答对生成**：目前尚缺data/qa/synth_world_llm_{train,dev}.jsonl。可复用gen_synth_qa.py或开发配套脚本（如gen_world_llm_qa.py），通过结合新生成的世界JSON与LocalGPT来创建引用这些事实的问答证据三元组

2. **质量管控**：在gen_world_llm.py中增加可选去重与日期范围校验功能（自动剔除或重新查询重复/超范围事实），确保每批数据要么符合标准，要么触发自动重试机制

3. **流水线与文档**：更新synth_world.yaml（或新增配置项）使阶段A指向synth_world_llm.jsonl，并在README.md/kblampp-implementation-guide.md中完整记录工作流程（世界生成与问答生成命令、环境要求）
